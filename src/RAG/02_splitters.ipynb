{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09991f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "data_dir = os.environ['DATA_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac60fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0325b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "\n",
    "#By default, the separator in CharacterTextSplitter is a newline character.\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "c_space_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be3bafe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghijklmnopqrstuvwxyz']\n",
      "['abcdefghijklmnopqrstuvwxyz']\n"
     ]
    }
   ],
   "source": [
    "text1 = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "print(r_splitter.split_text(text1))\n",
    "print(c_splitter.split_text(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af608dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefghijklmnopqrstuv', 'stuvwxyz']\n",
      "['abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz']\n"
     ]
    }
   ],
   "source": [
    "text2 = \"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\"\n",
    "print(r_splitter.split_text(text2))\n",
    "print(c_splitter.split_text(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7278688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z a b c d e f g h i', 'h i j k l m n o p q r s t', 's t u v w x y z']\n",
      "['a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z']\n",
      "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z a b c d e f g h i', 'h i j k l m n o p q r s t', 's t u v w x y z']\n"
     ]
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "print(r_splitter.split_text(text3))\n",
    "print(c_splitter.split_text(text3))\n",
    "print(c_space_splitter.split_text(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b9eaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The LangChain framework is designed to facilitate the development of applications \\\n",
    "that utilize large language models (LLMs). It provides a comprehensive set of tools and \\\n",
    "abstractions to streamline the process of building LLM-powered applications, \\\n",
    "making it easier for developers to create complex workflows and integrate various components. \\n\\n\\\n",
    "The framework includes features such as prompt management, memory handling, and \\\n",
    "data augmentation, allowing developers to focus on building their applications. \\n\\n\\\n",
    "LangChain supports a wide range of LLMs and can be easily extended to accommodate new models \\\n",
    "and use cases. It is particularly useful for tasks such as question answering, text generation, \\\n",
    "and conversational agents, enabling developers to leverage the power of LLMs in their applications \\\n",
    "with minimal effort.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da083aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LangChain framework is designed to facilitate the development of applications that utilize large language models (LLMs). It provides a comprehensive set of tools and abstractions to streamline the process of building LLM-powered applications, making it easier for developers to create complex workflows and integrate various components. \n",
      "\n",
      "The framework includes features such as prompt management, memory handling, and data augmentation, allowing developers to focus on building their applications. \n",
      "\n",
      "LangChain supports a wide range of LLMs and can be easily extended to accommodate new models and use cases. It is particularly useful for tasks such as question answering, text generation, and conversational agents, enabling developers to leverage the power of LLMs in their applications with minimal effort.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8748dd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split(\"\\n\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b5670e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split(\"\\n\\n\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "feae06e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split(\"\\n\\n\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f156d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=350,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=350,\n",
    "    chunk_overlap=0,\n",
    "    separator=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e33f9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The LangChain framework is designed to facilitate the development of applications that utilize large language models (LLMs). It provides a comprehensive set of tools and abstractions to streamline the process of building LLM-powered applications, making it easier for developers to create complex workflows and integrate various components. \\n\\nThe',\n",
       " 'framework includes features such as prompt management, memory handling, and data augmentation, allowing developers to focus on building their applications. \\n\\nLangChain supports a wide range of LLMs and can be easily extended to accommodate new models and use cases. It is particularly useful for tasks such as question answering, text generation, and',\n",
       " 'conversational agents, enabling developers to leverage the power of LLMs in their applications with minimal effort.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "023fa2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The LangChain framework is designed to facilitate the development of applications that utilize large language models (LLMs). It provides a comprehensive set of tools and abstractions to streamline the process of building LLM-powered applications, making it easier for developers to create complex workflows and integrate various components.',\n",
       " 'The framework includes features such as prompt management, memory handling, and data augmentation, allowing developers to focus on building their applications.',\n",
       " 'LangChain supports a wide range of LLMs and can be easily extended to accommodate new models and use cases. It is particularly useful for tasks such as question answering, text generation, and conversational agents, enabling developers to leverage the power of LLMs in their applications with minimal effort.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter_chunks = r_splitter.split_text(text)\n",
    "r_splitter_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de49935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The LangChain framework is designed to facilitate the development of applications that utilize large language models (LLMs). It provides a',\n",
       " 'comprehensive set of tools and abstractions to streamline the process of building LLM-powered applications, making it easier for developers to create',\n",
       " 'complex workflows and integrate various components.',\n",
       " 'The framework includes features such as prompt management, memory handling, and data augmentation, allowing developers to focus on building their',\n",
       " 'applications.',\n",
       " 'LangChain supports a wide range of LLMs and can be easily extended to accommodate new models and use cases. It is particularly useful for tasks such',\n",
       " 'as question answering, text generation, and conversational agents, enabling developers to leverage the power of LLMs in their applications with',\n",
       " 'minimal effort.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\.\", \" \", \"\"]\n",
    ")\n",
    "r_splitter_chunks = r_splitter.split_text(text)\n",
    "r_splitter_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b7b5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(f\"{data_dir}\\\\RAG\\\\PDF\\\\machinelearning-lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f8e67a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separator=\"\\n\",\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fdd0dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "476a5dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2819b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=1,\n",
    "    chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e8da905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo',\n",
       " ' bar',\n",
       " ' b',\n",
       " 'az',\n",
       " ' qu',\n",
       " 'x',\n",
       " ' qu',\n",
       " 'ux',\n",
       " ' cor',\n",
       " 'ge',\n",
       " ' gra',\n",
       " 'ult',\n",
       " ' gar',\n",
       " 'ply',\n",
       " ' w',\n",
       " 'aldo',\n",
       " ' f',\n",
       " 'red',\n",
       " ' pl',\n",
       " 'ugh',\n",
       " ' x',\n",
       " 'y',\n",
       " 'zzy',\n",
       " ' th',\n",
       " 'ud']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"foo bar baz qux quux corge grault garply waldo fred plugh xyzzy thud\"\n",
    "token_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d464f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'C:\\\\\\\\Users\\\\\\\\gunit\\\\\\\\OneDrive\\\\\\\\Documents\\\\\\\\Study Material\\\\\\\\Practice Projects\\\\\\\\remote\\\\\\\\artificial-intelligence\\\\\\\\data\\\\RAG\\\\PDF\\\\machinelearning-lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}, page_content='MachineLearning-Lecture01  \\n')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=10,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "docs = token_splitter.split_documents(pages)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc7f4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "da200d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Header 1\\n\\n\\\n",
    "This is some text under header 1.\\n\\n\\\n",
    "## Header 2\\n\\n\\\n",
    "This is some text under header 2.\\n\\n\\\n",
    "### Header 3\\n\\n\\\n",
    "This is some text under header 3.\\n\\n\\\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88791c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Header 1'}, page_content='This is some text under header 1.'),\n",
       " Document(metadata={'Header 1': 'Header 1', 'Header 2': 'Header 2'}, page_content='This is some text under header 2.'),\n",
       " Document(metadata={'Header 1': 'Header 1', 'Header 2': 'Header 2', 'Header 3': 'Header 3'}, page_content='This is some text under header 3.')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[\n",
    "        (\"#\", \"Header 1\"), \n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\")\n",
    "    ]\n",
    ")\n",
    "markdown_splitter.split_text(markdown_document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
